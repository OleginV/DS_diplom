{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9784b5",
   "metadata": {},
   "source": [
    "# SSA для динамики урожайности подсолнечника"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf6d86",
   "metadata": {},
   "source": [
    "## Загрузка необходимых библиотек и класса SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8935c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the usual suspects:\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Fiddle with figure settings here:\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['image.cmap'] = 'plasma'\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "# Set the default colour cycle (in case someone changes it...)\n",
    "from cycler import cycler\n",
    "cols = plt.get_cmap('tab10').colors\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=cols)\n",
    "\n",
    "# A simple little 2D matrix plotter, excluding x and y labels.\n",
    "def plot_2d(m, title=\"\"):\n",
    "    plt.imshow(m)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1dd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSA(object):\n",
    "    \n",
    "    __supported_types = (pd.Series, np.ndarray, list)\n",
    "    \n",
    "    def __init__(self, tseries, L, save_mem=True):\n",
    "        \"\"\"\n",
    "        Decomposes the given time series with a singular-spectrum analysis. Assumes the values of the time series are\n",
    "        recorded at equal intervals.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tseries : The original time series, in the form of a Pandas Series, NumPy array or list. \n",
    "        L : The window length. Must be an integer 2 <= L <= N/2, where N is the length of the time series.\n",
    "        save_mem : Conserve memory by not retaining the elementary matrices. Recommended for long time series with\n",
    "            thousands of values. Defaults to True.\n",
    "        \n",
    "        Note: Even if an NumPy array or list is used for the initial time series, all time series returned will be\n",
    "        in the form of a Pandas Series or DataFrame object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tedious type-checking for the initial time series\n",
    "        if not isinstance(tseries, self.__supported_types):\n",
    "            raise TypeError(\"Unsupported time series object. Try Pandas Series, NumPy array or list.\")\n",
    "        \n",
    "        # Checks to save us from ourselves\n",
    "        self.N = len(tseries)\n",
    "        if not 2 <= L <= self.N/2:\n",
    "            raise ValueError(\"The window length must be in the interval [2, N/2].\")\n",
    "        \n",
    "        self.L = L\n",
    "        self.orig_TS = pd.Series(tseries)\n",
    "        self.K = self.N - self.L + 1\n",
    "        \n",
    "        # Embed the time series in a trajectory matrix\n",
    "        self.X = np.array([self.orig_TS.values[i:L+i] for i in range(0, self.K)]).T\n",
    "        \n",
    "        # Decompose the trajectory matrix\n",
    "        self.U, self.Sigma, VT = np.linalg.svd(self.X)\n",
    "        self.d = np.linalg.matrix_rank(self.X)\n",
    "        \n",
    "        self.TS_comps = np.zeros((self.N, self.d))\n",
    "        \n",
    "        if not save_mem:\n",
    "            # Construct and save all the elementary matrices\n",
    "            self.X_elem = np.array([ self.Sigma[i]*np.outer(self.U[:,i], VT[i,:]) for i in range(self.d) ])\n",
    "\n",
    "            # Diagonally average the elementary matrices, store them as columns in array.           \n",
    "            for i in range(self.d):\n",
    "                X_rev = self.X_elem[i, ::-1]\n",
    "                self.TS_comps[:,i] = [X_rev.diagonal(j).mean() for j in range(-X_rev.shape[0]+1, X_rev.shape[1])]\n",
    "            \n",
    "            self.V = VT.T\n",
    "        else:\n",
    "            # Reconstruct the elementary matrices without storing them\n",
    "            for i in range(self.d):\n",
    "                X_elem = self.Sigma[i]*np.outer(self.U[:,i], VT[i,:])\n",
    "                X_rev = X_elem[::-1]\n",
    "                self.TS_comps[:,i] = [X_rev.diagonal(j).mean() for j in range(-X_rev.shape[0]+1, X_rev.shape[1])]\n",
    "            \n",
    "            self.X_elem = \"Re-run with save_mem=False to retain the elementary matrices.\"\n",
    "            \n",
    "            # The V array may also be very large under these circumstances, so we won't keep it.\n",
    "            self.V = \"Re-run with save_mem=False to retain the V matrix.\"\n",
    "        \n",
    "        # Calculate the w-correlation matrix.\n",
    "        self.calc_wcorr()\n",
    "            \n",
    "    def components_to_df(self, n=0):\n",
    "        \"\"\"\n",
    "        Returns all the time series components in a single Pandas DataFrame object.\n",
    "        \"\"\"\n",
    "        if n > 0:\n",
    "            n = min(n, self.d)\n",
    "        else:\n",
    "            n = self.d\n",
    "        \n",
    "        # Create list of columns - call them F0, F1, F2, ...\n",
    "        cols = [\"F{}\".format(i) for i in range(n)]\n",
    "        return pd.DataFrame(self.TS_comps[:, :n], columns=cols, index=self.orig_TS.index)\n",
    "            \n",
    "    \n",
    "    def reconstruct(self, indices):\n",
    "        \"\"\"\n",
    "        Reconstructs the time series from its elementary components, using the given indices. Returns a Pandas Series\n",
    "        object with the reconstructed time series.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        indices: An integer, list of integers or slice(n,m) object, representing the elementary components to sum.\n",
    "        \"\"\"\n",
    "        if isinstance(indices, int): indices = [indices]\n",
    "        \n",
    "        ts_vals = self.TS_comps[:,indices].sum(axis=1)\n",
    "        return pd.Series(ts_vals, index=self.orig_TS.index)\n",
    "    \n",
    "    def calc_wcorr(self):\n",
    "        \"\"\"\n",
    "        Calculates the w-correlation matrix for the time series.\n",
    "        \"\"\"\n",
    "             \n",
    "        # Calculate the weights\n",
    "        w = np.array(list(np.arange(self.L)+1) + [self.L]*(self.K-self.L-1) + list(np.arange(self.L)+1)[::-1])\n",
    "        \n",
    "        def w_inner(F_i, F_j):\n",
    "            return w.dot(F_i*F_j)\n",
    "        \n",
    "        # Calculated weighted norms, ||F_i||_w, then invert.\n",
    "        F_wnorms = np.array([w_inner(self.TS_comps[:,i], self.TS_comps[:,i]) for i in range(self.d)])\n",
    "        F_wnorms = F_wnorms**-0.5\n",
    "        \n",
    "        # Calculate Wcorr.\n",
    "        self.Wcorr = np.identity(self.d)\n",
    "        for i in range(self.d):\n",
    "            for j in range(i+1,self.d):\n",
    "                self.Wcorr[i,j] = abs(w_inner(self.TS_comps[:,i], self.TS_comps[:,j]) * F_wnorms[i] * F_wnorms[j])\n",
    "                self.Wcorr[j,i] = self.Wcorr[i,j]\n",
    "    \n",
    "    def plot_wcorr(self, min=None, max=None):\n",
    "        \"\"\"\n",
    "        Plots the w-correlation matrix for the decomposed time series.\n",
    "        \"\"\"\n",
    "        if min is None:\n",
    "            min = 0\n",
    "        if max is None:\n",
    "            max = self.d\n",
    "        \n",
    "        if self.Wcorr is None:\n",
    "            self.calc_wcorr()\n",
    "        \n",
    "        ax = plt.imshow(self.Wcorr)\n",
    "        plt.xlabel(r\"$\\tilde{F}_i$\")\n",
    "        plt.ylabel(r\"$\\tilde{F}_j$\")\n",
    "        plt.colorbar(ax.colorbar, fraction=0.045)\n",
    "        ax.colorbar.set_label(\"$W_{i,j}$\")\n",
    "        plt.clim(0,1)\n",
    "        \n",
    "        # For plotting purposes:\n",
    "        if max == self.d:\n",
    "            max_rnge = self.d-1\n",
    "        else:\n",
    "            max_rnge = max\n",
    "        \n",
    "        plt.xlim(min-0.5, max_rnge+0.5)\n",
    "        plt.ylim(max_rnge+0.5, min-0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859c5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssa_sample(ssa_rec, start_year=2007):\n",
    "    ## Создание фрейма с данными по тренду урожайности\n",
    "    # Добавление данных тренда урожайности\n",
    "    trend = pd.DataFrame(ssa_rec, columns=['trend_yield']).reset_index()\n",
    "\n",
    "    # Добавление данных ежегодного изменения урожайности по тренду\n",
    "    trends = []\n",
    "    for i in trend.index:\n",
    "        if i==min(trend.index):\n",
    "            el = 0\n",
    "        else:\n",
    "            el = trend.trend_yield[i]-trend.trend_yield[i-1] # изменение тренда Y-o-Y\n",
    "        trends.append(el)\n",
    "    trend['diff_yield'] = trends\n",
    "\n",
    "    # Добавление данных кумулятивного ежегодного изменения урожайности с 2007 года\n",
    "    diff_trend = []\n",
    "    diff = trend.loc[(trend['year'] >=start_year), ['year','diff_yield']].reset_index()\n",
    "    for i in diff.index:\n",
    "        string=[]\n",
    "        if i==min(diff.index):\n",
    "            el = diff.diff_yield[i]\n",
    "            y = diff.year[i]\n",
    "            string.append(y)\n",
    "            string.append(el)\n",
    "        else:\n",
    "            el = sum(diff.diff_yield[:i+1]) # кумулятивное изменение тренда с 2007 года\n",
    "            y = diff.year[i]\n",
    "            string.append(y)\n",
    "            string.append(el)\n",
    "        diff_trend.append(string)\n",
    "    diff_trend = pd.DataFrame(diff_trend, columns=['year', 'diff_cumulative'])\n",
    "\n",
    "    # Добавление данных в общий датафрейм\n",
    "    trend = pd.merge(trend, diff_trend, how='left', on=['year'])\n",
    "    \n",
    "    return trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1644df6",
   "metadata": {},
   "source": [
    "## 1. Анализ динамики урожайности подсолнечника с помощью метода SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e5cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Чтение данных из файла\n",
    "file = pd.read_csv(\"INPUT/SSA_hist_yield.csv.zip\", compression='zip', sep=';', header=0, decimal=','\n",
    "                   , quotechar='\"', dtype={'yield_code': 'object'})\n",
    "hist = pd.read_csv(\"INPUT/historical_yields.csv.zip\", compression='zip', sep=';', header=0, decimal=','\n",
    "                   , quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e641e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990 entries, 0 to 989\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   region      990 non-null    object \n",
      " 1   year        990 non-null    int64  \n",
      " 2   yield       990 non-null    float64\n",
      " 3   yield_code  990 non-null    object \n",
      " 4   fed_code    990 non-null    int64  \n",
      " 5   reg_code    990 non-null    int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 46.5+ KB\n"
     ]
    }
   ],
   "source": [
    "## Просмотр информации из файла\n",
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a01549",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun = file.loc[(file['year'] >=2000), ['year','yield']]\n",
    "#sun = file.loc[(file['year'] >=1950), ['year','yield']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ee1bd",
   "metadata": {},
   "source": [
    "### 1.1 Сингулярный спектральный анализ данных по субъектам РФ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebb614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_wind = 11\n",
    "list_ssa = []\n",
    "for reg in file.yield_code.unique():\n",
    "    sun = file.loc[(file['yield_code'] ==reg), ['year','yield']]\n",
    "    ## Подготовка датафрейма для проведения анализа SSA\n",
    "    yields = pd.Series(sun['yield'])\n",
    "    yields.index = sun['year']\n",
    "    ssa_results = SSA(yields, L_wind)\n",
    "    ssa_rec = ssa_results.reconstruct(0)\n",
    "    data = ssa_sample(ssa_rec, start_year=2007)\n",
    "    data['yield_code'] = reg\n",
    "    list_ssa.append(data)\n",
    "data_ssa = pd.concat(list_ssa, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e9ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Сохранение данных в файл csv\n",
    "file_ssa = data_ssa.to_csv('DATA/data_ssa.csv.gz', sep=';', index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1ae65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
